# Dylan Bouchard

Principal Applied Scientist @ [CVS Health](https://github.com/cvs-health)  
*AI Safety | Uncertainty Quantification | Hallucination Detection | Bias & Fairness*

I lead CVS Health's first AI research program, focusing on Responsible AI and AI Safety. My work bridges cutting-edge research with practical implementation through open-source toolkits.

## üîì Open-Source Projects
- [**UQLM**](https://github.com/cvs-health/uqlm) - State-of-the-art uncertainty quantification for LLM hallucination detection
- [**LangFair**](https://github.com/cvs-health/langfair) - Context-aware LLM bias and fairness assessment framework

## üìù Select Research
- [**A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers**](https://arxiv.org/abs/2504.19254) (under review at TMLR)
- [**UQLM: A Python Package for Uncertainty Quantification in LLMs**](https://arxiv.org/abs/2507.06196) (under review at JMLR)
- [**An Actionable Framework for Assessing Bias and Fairness in LLM Use Cases**](https://arxiv.org/abs/2407.10853) (under review at ACM TIST)
- [**LangFair: A Python Package for Assessing Bias and Fairness in LLM Use Cases**](https://joss.theoj.org/papers/10.21105/joss.07570) (Journal of Open Source Software)

## üì´ Connect
- [LinkedIn](https://www.linkedin.com/in/dylan-bouchard-phd-52594664/)
- [Google Scholar](https://scholar.google.com/citations?user=nOoGEjUAAAAJ&hl=en)
- Email: dbouchard92@gmail.com
